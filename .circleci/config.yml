
version: 2.1
commands:
  print_command_one:
    description: "printing a text"
    parameters:
      to:
        type: string
        default: "Learning commands"
    steps:
      - run: echo << parameters.to >>
  print_envs:
    description: "to Print command environment variables"
    steps:
      - run: echo "Job is ${CIRCLE_JOB} and workflow is ${CIRCLE_WORKFLOW_ID:0:2}. The pipeline id is << pipeline.id >>"
  destroy_environment:
    steps:
      - run:
          name: Destroy environment
          command: |
            aws cloudformation delete-stack --stack-name pro-${CIRCLE_WORKFLOW_ID}
executors:
  general-executor:
    docker:
      - image: circleci/ruby:2.4.1
  lw_executor:
    docker:
      - image: circleci/node:13.8.0
orbs:
  node: circleci/node@1.1
jobs:
  
  second_job:
    executor: general-executor # this uses a predefined docker image for execution
    steps:
      - checkout
      - run: echo "This is second Job without sleep"
  first_job:
    executor: general-executor # predefined
    steps:
      - checkout
      - run: echo "Echo with sleep"
      - run: sleep 10
      - run: echo "My pipeline id is << pipeline.id >> and my git branch is << pipeline.git.branch >>"
  print_envs:
    environment:
      MY_NAME: "Pius pipeline"
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - run: echo "${MY_NAME} other env ${CIRCLE_WORKFLOW_ID:0:2} "
      - run: echo "Circle job is ${CIRCLE_JOB} and pull request username is ${CIRCLE_PR_USERNAME}"
      - print_envs
  create_file_to_share:
    docker:
      - image: circleci/node:13.8.0
    steps:
     - checkout
     #- run: mkdir ~/tmp/workspace
     - run: mkdir ~/tmp
     - run: mkdir ~/tmp/workspace
     - run: echo "value to store in file" > ~/tmp/workspace/output.txt #tmp/workspace/output.txt

     - persist_to_workspace: # this saves a file to workspace for sharing
        root: ~/tmp/workspace #required for persist workspace. It can be an absolute path or one relative to pwd
        paths: #paths relative to the workspace  root. Must not be root itself
          #- file/share/output.txt #directory /tmp/workspace/file/share now exiists
          #- share      # directory /tmp/workspace/share now exists.
          - output.txt
  print_out_workspace:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - run: echo "This is attach to workspace"
      - attach_workspace:
          at: ~/tmp/workspace     #/tmp/workspace
      - run: cat ~/tmp/workspace/output.txt  #tmp/workspace/output.txt
  using_commands:
    executor: general-executor
    steps:
      - print_command_one:
          to: "Your first print job using a defined command!"
  testing_failure:
    executor: lw_executor
    steps:
      - run: return 1 #this step simply fails
      - run:
          name: on error 
          command: echo "Failed" 
          when: on_fail
  create_infrastructure:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Ensure backend infrastructure exists
          command: |
            aws cloudformation deploy \
              --template-file template3.yml \
              --stack-name MyStack2
  
  configure_infrastructure: #job to configure infrastructure
    docker:
      - image: python:3.7-alpine3.11
    steps:
      - checkout
      - run: mkdir -p ~/.ssh
      - checkout
      - run: echo 'ec2-18-219-250-43.us-east-2.compute.amazonaws.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCUmOUlbJ+1ZbWne6K7p7aPJbPsC7vF0WoQmEGPPOUJk9eXcFwghAkQFBCiWci0n28wMxHRxg7M+fdTrnON8GBdCcL+jUC0KquR5Hz1dMs6OGXdqBw444EudZkHpm7Fm1WqjCkRvI12T23n//Zmw6nQuwI0lyNECEslgLg+mW5H/bHRMFV9CJ/Jfqdad5HsW+e4jQAJ/enLd05qoAcOkfKC37bhiFHYqJEPciO368TjVforyFP1/DQSAWZXFyPWzpjgj6PuOtlNA/OAAe9Yw9DeyQiiEdU0kdSdLDReUG4e2L6IA+k8ddkZ/nmr/sP3ZmQ88D/vg7l+70Mekg4kDmaH' >> ~/.ssh/known_hosts
      - add_ssh_keys:
          fingerprints: 
            - '34:fb:e6:69:96:ef:69:7c:6d:de:98:a9:e0:c4:01:1c'
      - run: 
         name: install dependencies
         command: |
           apk add --update ansible #install the dependencies 
      - run:
         name: Configure server #the ssh -o should be a workaround for the continues failure to log in to the server
         command: |
          # ssh -o StrictHostKeyChecking=no ubuntu@ec2-18-219-250-43.us-east-2.compute.amazonaws.com exit
          ansible-playbook -i inventory2.txt main-remote.yml #mainremote represents the plabook with instructions to execute
  smoke_test:
    docker:
      - image: alpine:latest
    steps:
      - run: apk add --update curl
      - run:
          name: smoke test.
          command: |
            URL="https://blog.udacity.com/"
            if curl -s --head ${URL} # test if blog.udacity. com exists
            then
              return 0
            else
              return 1
            fi
  create_infrastructure2: #implementing rollback. This happens when a failure occurs. 
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Create Stack
          command: |
            aws cloudformation deploy \
              --template-file template3.yml \
              --stack-name prod-${CIRCLE_WORKFLOW_ID}
      - run: return 1
      - destroy_environment
      - when: on_fail
  create_and_deploy_front_end: # job that deploys files each time to the server
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Create frontend and destroy old front end
          command: |
            aws cloudformation deploy \
              --template-file bucket.yml \
              --stack-name "${CIRCLE_WORKFLOW_ID:0:7}" \
              --parameter-overrides PipelineID="${CIRCLE_WORKFLOW_ID:0:7}"
      - run: aws s3 sync . s3://"${CIRCLE_WORKFLOW_ID}" -- delete 
      
  get_last_deployment_id:  #job to query the id of the latest deployed service. We query and save the command in accessible worspace
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run: mkdir ~/tmp
      - run: mkdir ~/tmp/workspace
      - run:
          name: Query ID
          command: |
            aws cloudformation \
              list-exports --query "Exports[?Name==\`PipelineID\`].Value" \
              --no-paginate --output text > ~/tmp/workspace/lastId.txt
      - persist_to_workspace: # this saves a file to workspace for sharing
          root: ~/tmp/workspace #required for persist workspace. It can be an absolute path or one relative to pwd
          paths: #paths relative to the workspace  root. Must not be root itself
            - lastId.txt
  promote_to_production: # executes cloudfront  
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: promote to production newly deployed
          command: | 
            aws cloudformation deploy \
              --template-file cloudfront.yml \
              --stack-name production-distro \
              --parameter-overrides PipelineID="${CIRCLE_WORKFLOW_ID}" 
  clean_up_old_front_end: # destroys previous production on S3
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - attach_workspace:
          at: ~/tmp/workspace
      - run: PreviousPipelineID="$(cat ~/tmp/workspace/lastId.txt | base64)"
      - run:
          name: Clean-up old front end
          command: |
            aws s3 rm "s3://${OldPipelineID}" --recursive
            aws cloudformation delete-stack --stack-name "${PreviousPipelineID}"

# BUCKET ENDPOINT
# http://bucket1udacity.s3-website.us-east-2.amazonaws.com

workflows: # workflow is used to coordinate job execution. Some jobs may only get executed after others
  version: 2.1
  workflow_name: #use any convenient name for the workflow
    jobs: #list the jobs this workflow should run
      - second_job
      - first_job:
          requires:
            - second_job
      - print_envs
      - print_out_workspace:
          requires:
            - create_file_to_share
      - create_file_to_share
      - using_commands
      - testing_failure #this job is meant to fail. No alarm.
      - create_infrastructure #this should work not working yet
      - smoke_test # run a test on server
      - create_infrastructure2
      - configure_infrastructure:
          requires:
           - create_infrastructure
      - create_and_deploy_front_end
      - get_last_deployment_id:
          requires:
            - create_and_deploy_front_end
      - promote_to_production:
          requires:
            - get_last_deployment_id
      - clean_up_old_front_end:
          requires:
            - promote_to_production
